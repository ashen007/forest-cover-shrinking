@article{WANG2023110415,
title = {Orientation Attention Network for semantic segmentation of remote sensing images},
journal = {Knowledge-Based Systems},
volume = {267},
pages = {110415},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110415},
url = {https://www.sciencedirect.com/science/article/pii/S095070512300165X},
author = {Junxiao Wang and Zhixi Feng and Yao Jiang and Shuyuan Yang and Huixiao Meng},
keywords = {Semantic segmentation, Remote sensing images, Asymmetrical convolution, Orientation attention},
abstract = {With the increasing resolution of remote sensing images, semantic segmentation has become a challenging task for the extremely abundant textures and edges that existed in images. In this paper, an Orientation Attention Network (OANet) is proposed to learn both orientation features and global semantic features of ground objects for accurate segmentation. Firstly, an Asymmetrical Convolution (AC) is constructed to explore the directional anisotropy of objects. Then an Orientation Attention Module (OAM) is advanced to enhance the intrinsic geometric features of objects, by defining two branches with stacked asymmetrical convolutions along the coordinate axis and adaptively selecting features which are beneficial for segmentation. Finally, the OANet, which combines OAM with a Global Feature Module (GFM), is proposed for both structural and semantic sensitive representations of images. Extensive experiments on four well-known public datasets show the effectiveness of the OANet.}
}